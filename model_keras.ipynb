{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las categorías\n",
    "categories = ['auto', 'casa', 'edificio', 'gato', 'moto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las dimensiones de las imagenes\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de un diccionario para mapear los nombres de las imagenes a las categorias\n",
    "category_map = {}\n",
    "for img_name in os.listdir('dataset/train'):\n",
    "    for category in categories:\n",
    "        if category in img_name:\n",
    "            category_map[img_name] = categories.index(category)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de un diccionario para mapear los nombres de las imagenes a las categorias\n",
    "category_map2 = {}\n",
    "for img_name in os.listdir('dataset/test'):\n",
    "    for category in categories:\n",
    "        if category in img_name:\n",
    "            category_map2[img_name] = categories.index(category)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de las imagenes de entrenamiento\n",
    "X_train = []\n",
    "y_train = []\n",
    "for img_name in os.listdir('dataset/train'):\n",
    "    img = load_img(os.path.join('dataset/train', img_name), target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img)\n",
    "    X_train.append(img_array)\n",
    "    y_train.append(category_map[img_name])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de las imagenes de test\n",
    "X_test = []\n",
    "y_test = []\n",
    "for img_name in os.listdir('dataset/test'):\n",
    "    img = load_img(os.path.join('dataset/test', img_name), target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img)\n",
    "    X_test.append(img_array)\n",
    "    y_test.append(category_map2[img_name])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la forma de entrada\n",
    "input_shape = (img_height, img_width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la capa de entrada\n",
    "input_layer = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las capas convolucionales\n",
    "x = Conv2D(512, (3, 3), activation='relu')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la capa Flatten\n",
    "x = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las capas densas\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(len(categories), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la capa de salida\n",
    "output_layer = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 0.2500 - loss: 3.3821 - val_accuracy: 0.0000e+00 - val_loss: 182.5314\n",
      "Epoch 2/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 0.2500 - loss: 151.2140 - val_accuracy: 0.0000e+00 - val_loss: 35.1597\n",
      "Epoch 3/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.2500 - loss: 35.1459 - val_accuracy: 0.0000e+00 - val_loss: 24.1240\n",
      "Epoch 4/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.2500 - loss: 13.4877 - val_accuracy: 0.0000e+00 - val_loss: 9.9124\n",
      "Epoch 5/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.2500 - loss: 4.6563 - val_accuracy: 0.0000e+00 - val_loss: 6.8356\n",
      "Epoch 6/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.2500 - loss: 2.3576 - val_accuracy: 0.0000e+00 - val_loss: 5.3678\n",
      "Epoch 7/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.2857 - loss: 1.4106 - val_accuracy: 0.0000e+00 - val_loss: 5.4126\n",
      "Epoch 8/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.2500 - loss: 1.3585 - val_accuracy: 0.0000e+00 - val_loss: 6.1174\n",
      "Epoch 9/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.4286 - loss: 1.2406 - val_accuracy: 0.0000e+00 - val_loss: 6.7246\n",
      "Epoch 10/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.4643 - loss: 1.1853 - val_accuracy: 0.0000e+00 - val_loss: 7.2807\n",
      "Epoch 11/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.6071 - loss: 1.0986 - val_accuracy: 0.0000e+00 - val_loss: 8.0690\n",
      "Epoch 12/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6786 - loss: 0.9918 - val_accuracy: 0.0000e+00 - val_loss: 8.9397\n",
      "Epoch 13/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6429 - loss: 0.9410 - val_accuracy: 0.0000e+00 - val_loss: 10.6310\n",
      "Epoch 14/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.4643 - loss: 1.2696 - val_accuracy: 0.0000e+00 - val_loss: 11.1153\n",
      "Epoch 15/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.2857 - loss: 1.4743 - val_accuracy: 0.0000e+00 - val_loss: 11.7738\n",
      "Epoch 16/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.3929 - loss: 1.2565 - val_accuracy: 0.0000e+00 - val_loss: 13.0118\n",
      "Epoch 17/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.3214 - loss: 1.1207 - val_accuracy: 0.0000e+00 - val_loss: 11.8816\n",
      "Epoch 18/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 1.1386 - val_accuracy: 0.0000e+00 - val_loss: 11.0716\n",
      "Epoch 19/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7500 - loss: 0.8201 - val_accuracy: 0.0000e+00 - val_loss: 11.4740\n",
      "Epoch 20/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.6786 - loss: 0.9274 - val_accuracy: 0.0000e+00 - val_loss: 10.8050\n",
      "Epoch 21/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.5357 - loss: 0.8845 - val_accuracy: 0.0000e+00 - val_loss: 10.4285\n",
      "Epoch 22/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.6786 - loss: 0.7135 - val_accuracy: 0.0000e+00 - val_loss: 10.4396\n",
      "Epoch 23/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8571 - loss: 0.6395 - val_accuracy: 0.0000e+00 - val_loss: 10.8733\n",
      "Epoch 24/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.8929 - loss: 0.6355 - val_accuracy: 0.0000e+00 - val_loss: 11.0120\n",
      "Epoch 25/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.8929 - loss: 0.5056 - val_accuracy: 0.0000e+00 - val_loss: 11.1547\n",
      "Epoch 26/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.8929 - loss: 0.4384 - val_accuracy: 0.0000e+00 - val_loss: 12.3416\n",
      "Epoch 27/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.9286 - loss: 0.3283 - val_accuracy: 0.0000e+00 - val_loss: 14.5193\n",
      "Epoch 28/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.9643 - loss: 0.2672 - val_accuracy: 0.0000e+00 - val_loss: 16.1583\n",
      "Epoch 29/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.9643 - loss: 0.1916 - val_accuracy: 0.0000e+00 - val_loss: 18.2109\n",
      "Epoch 30/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.1840 - val_accuracy: 0.0000e+00 - val_loss: 20.6286\n",
      "Epoch 31/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.9286 - loss: 0.1656 - val_accuracy: 0.0000e+00 - val_loss: 23.2931\n",
      "Epoch 32/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.1112 - val_accuracy: 0.0000e+00 - val_loss: 23.6581\n",
      "Epoch 33/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 0.0000e+00 - val_loss: 25.0817\n",
      "Epoch 34/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0615 - val_accuracy: 0.0000e+00 - val_loss: 27.0836\n",
      "Epoch 35/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.0000e+00 - val_loss: 29.4795\n",
      "Epoch 36/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.0000e+00 - val_loss: 31.8584\n",
      "Epoch 37/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.0000e+00 - val_loss: 32.9706\n",
      "Epoch 38/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.0000e+00 - val_loss: 34.0072\n",
      "Epoch 39/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.0000e+00 - val_loss: 35.4649\n",
      "Epoch 40/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 37.1040\n",
      "Epoch 41/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.0000e+00 - val_loss: 38.7586\n",
      "Epoch 42/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.0000e+00 - val_loss: 40.4299\n",
      "Epoch 43/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 9.2438e-04 - val_accuracy: 0.0000e+00 - val_loss: 42.1089\n",
      "Epoch 44/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 7.0697e-04 - val_accuracy: 0.0000e+00 - val_loss: 43.7014\n",
      "Epoch 45/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.0000e+00 - val_loss: 45.0844\n",
      "Epoch 46/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0000e+00 - val_loss: 46.2418\n",
      "Epoch 47/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 1.0000 - loss: 8.0200e-04 - val_accuracy: 0.0000e+00 - val_loss: 47.1977\n",
      "Epoch 48/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 6.6811e-04 - val_accuracy: 0.0000e+00 - val_loss: 47.9730\n",
      "Epoch 49/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 6.1364e-04 - val_accuracy: 0.0000e+00 - val_loss: 48.5520\n",
      "Epoch 50/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 4.8483e-04 - val_accuracy: 0.0000e+00 - val_loss: 48.9877\n",
      "Epoch 51/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 3.2336e-04 - val_accuracy: 0.0000e+00 - val_loss: 49.3501\n",
      "Epoch 52/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 2.1309e-04 - val_accuracy: 0.0000e+00 - val_loss: 49.6722\n",
      "Epoch 53/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 1.0000 - loss: 1.6057e-04 - val_accuracy: 0.0000e+00 - val_loss: 49.9858\n",
      "Epoch 54/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 1.4295e-04 - val_accuracy: 0.0000e+00 - val_loss: 50.3117\n",
      "Epoch 55/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 1.3669e-04 - val_accuracy: 0.0000e+00 - val_loss: 50.6345\n",
      "Epoch 56/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 1.0000 - loss: 1.2845e-04 - val_accuracy: 0.0000e+00 - val_loss: 50.9589\n",
      "Epoch 57/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 1.1679e-04 - val_accuracy: 0.0000e+00 - val_loss: 51.2827\n",
      "Epoch 58/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0435e-04 - val_accuracy: 0.0000e+00 - val_loss: 51.6104\n",
      "Epoch 59/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 9.2680e-05 - val_accuracy: 0.0000e+00 - val_loss: 51.9431\n",
      "Epoch 60/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 8.1706e-05 - val_accuracy: 0.0000e+00 - val_loss: 52.2803\n",
      "Epoch 61/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 7.0635e-05 - val_accuracy: 0.0000e+00 - val_loss: 52.6297\n",
      "Epoch 62/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 5.9520e-05 - val_accuracy: 0.0000e+00 - val_loss: 52.9756\n",
      "Epoch 63/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 4.8713e-05 - val_accuracy: 0.0000e+00 - val_loss: 53.3312\n",
      "Epoch 64/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 3.8755e-05 - val_accuracy: 0.0000e+00 - val_loss: 53.6950\n",
      "Epoch 65/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 2.9902e-05 - val_accuracy: 0.0000e+00 - val_loss: 54.0698\n",
      "Epoch 66/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 2.2112e-05 - val_accuracy: 0.0000e+00 - val_loss: 54.4594\n",
      "Epoch 67/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 1.5741e-05 - val_accuracy: 0.0000e+00 - val_loss: 54.8584\n",
      "Epoch 68/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 1.1600e-05 - val_accuracy: 0.0000e+00 - val_loss: 55.2492\n",
      "Epoch 69/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 8.6546e-06 - val_accuracy: 0.0000e+00 - val_loss: 55.6289\n",
      "Epoch 70/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 6.4965e-06 - val_accuracy: 0.0000e+00 - val_loss: 55.9924\n",
      "Epoch 71/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 4.8831e-06 - val_accuracy: 0.0000e+00 - val_loss: 56.3347\n",
      "Epoch 72/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 3.6996e-06 - val_accuracy: 0.0000e+00 - val_loss: 56.6572\n",
      "Epoch 73/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 2.8823e-06 - val_accuracy: 0.0000e+00 - val_loss: 56.9618\n",
      "Epoch 74/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 2.3629e-06 - val_accuracy: 0.0000e+00 - val_loss: 57.2503\n",
      "Epoch 75/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 2.0265e-06 - val_accuracy: 0.0000e+00 - val_loss: 57.5211\n",
      "Epoch 76/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 1.8520e-06 - val_accuracy: 0.0000e+00 - val_loss: 57.7723\n",
      "Epoch 77/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.7881e-06 - val_accuracy: 0.0000e+00 - val_loss: 58.0037\n",
      "Epoch 78/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.8094e-06 - val_accuracy: 0.0000e+00 - val_loss: 58.2166\n",
      "Epoch 79/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.8946e-06 - val_accuracy: 0.0000e+00 - val_loss: 58.4096\n",
      "Epoch 80/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 2.0436e-06 - val_accuracy: 0.0000e+00 - val_loss: 58.5825\n",
      "Epoch 81/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 2.2351e-06 - val_accuracy: 0.0000e+00 - val_loss: 58.7341\n",
      "Epoch 82/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 2.4267e-06 - val_accuracy: 0.0000e+00 - val_loss: 58.8633\n",
      "Epoch 83/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 2.6098e-06 - val_accuracy: 0.0000e+00 - val_loss: 58.9688\n",
      "Epoch 84/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 2.7418e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0491\n",
      "Epoch 85/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 2.7843e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1061\n",
      "Epoch 86/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 2.7077e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1428\n",
      "Epoch 87/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 2.5374e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1625\n",
      "Epoch 88/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 2.3288e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1690\n",
      "Epoch 89/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 2.1117e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1668\n",
      "Epoch 90/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.9116e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1594\n",
      "Epoch 91/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.7455e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1490\n",
      "Epoch 92/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.5965e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1368\n",
      "Epoch 93/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.4901e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1236\n",
      "Epoch 94/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 1.3922e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1104\n",
      "Epoch 95/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.3198e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0980\n",
      "Epoch 96/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.2645e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0867\n",
      "Epoch 97/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.2176e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0770\n",
      "Epoch 98/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 1.1963e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0698\n",
      "Epoch 99/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1751e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0648\n",
      "Epoch 100/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1538e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0613\n",
      "Epoch 101/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1410e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0592\n",
      "Epoch 102/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1325e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0588\n",
      "Epoch 103/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1240e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0599\n",
      "Epoch 104/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1282e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0627\n",
      "Epoch 105/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1282e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0671\n",
      "Epoch 106/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 1.1240e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0731\n",
      "Epoch 107/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.1240e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0804\n",
      "Epoch 108/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.1240e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0891\n",
      "Epoch 109/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.1197e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.0991\n",
      "Epoch 110/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.1155e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1103\n",
      "Epoch 111/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 1.1112e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1227\n",
      "Epoch 112/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.1069e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1360\n",
      "Epoch 113/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.0984e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1503\n",
      "Epoch 114/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0942e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1654\n",
      "Epoch 115/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.0857e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1813\n",
      "Epoch 116/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0771e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.1979\n",
      "Epoch 117/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.0686e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.2151\n",
      "Epoch 118/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0601e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.2328\n",
      "Epoch 119/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 1.0558e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.2510\n",
      "Epoch 120/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0346e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.2696\n",
      "Epoch 121/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0303e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.2885\n",
      "Epoch 122/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0175e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.3076\n",
      "Epoch 123/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0090e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.3269\n",
      "Epoch 124/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0048e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.3463\n",
      "Epoch 125/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 1.0005e-06 - val_accuracy: 0.0000e+00 - val_loss: 59.3659\n",
      "Epoch 126/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 9.9199e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.3856\n",
      "Epoch 127/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 9.8347e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.4053\n",
      "Epoch 128/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 9.7496e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.4249\n",
      "Epoch 129/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 9.6644e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.4445\n",
      "Epoch 130/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 9.5793e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.4639\n",
      "Epoch 131/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 9.4941e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.4831\n",
      "Epoch 132/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 9.4516e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.5021\n",
      "Epoch 133/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 9.3664e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.5209\n",
      "Epoch 134/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 9.2813e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.5394\n",
      "Epoch 135/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 9.2813e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.5577\n",
      "Epoch 136/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 9.1961e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.5757\n",
      "Epoch 137/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 9.1110e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.5934\n",
      "Epoch 138/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 9.0684e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.6109\n",
      "Epoch 139/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 8.9832e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.6281\n",
      "Epoch 140/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 8.9407e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.6450\n",
      "Epoch 141/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.9407e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.6616\n",
      "Epoch 142/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.9407e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.6780\n",
      "Epoch 143/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.8555e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.6941\n",
      "Epoch 144/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.8129e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.7101\n",
      "Epoch 145/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 8.6852e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.7258\n",
      "Epoch 146/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.6852e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.7413\n",
      "Epoch 147/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.6427e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.7566\n",
      "Epoch 148/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.6001e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.7717\n",
      "Epoch 149/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 8.5149e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.7866\n",
      "Epoch 150/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 8.5149e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.8013\n",
      "Epoch 151/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 8.4298e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.8160\n",
      "Epoch 152/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.3446e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.8306\n",
      "Epoch 153/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.3021e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.8450\n",
      "Epoch 154/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.3021e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.8595\n",
      "Epoch 155/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.2595e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.8739\n",
      "Epoch 156/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.2595e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.8883\n",
      "Epoch 157/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 8.1318e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.9027\n",
      "Epoch 158/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.0892e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.9171\n",
      "Epoch 159/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 8.0466e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.9315\n",
      "Epoch 160/160\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 8.0040e-07 - val_accuracy: 0.0000e+00 - val_loss: 59.9459\n",
      "CPU times: total: 5h 3min 20s\n",
      "Wall time: 38min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26afc3d2570>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "ajuste = %time model.fit(X_train, y_train, epochs=160, batch_size=32, validation_split=0.2)\n",
    "ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6000 - loss: 14.8043\n",
      "Test accuracy: 0.60\n",
      "Test loss: 14.80\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo con datos de test para obtener información aproximada en cuanto al funcionamiento del modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy:.2f}')\n",
    "print(f'Test loss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado en un archivo .h5\n",
    "model.save('mi_modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to mi_modelo.onnx\n"
     ]
    }
   ],
   "source": [
    "# Convertir el modelo Keras guardado a ONNX utilizando td2onnx\n",
    "spec = (tf.TensorSpec((None, img_height, img_width, 3), tf.float32, name=\"input\"),)\n",
    "output_path = \"mi_modelo.onnx\"\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "\n",
    "print(f'Model saved to {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
